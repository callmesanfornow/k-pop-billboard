{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "\n",
    "def load_data(folder_path):\n",
    "    all_data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "\n",
    "            # Load CSV and add chart_date column\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, engine='python', encoding='utf-8')\n",
    "            # print(f\"Loaded {file_path} with shape {df.shape}\")\n",
    "\n",
    "            all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Load data\n",
    "hot100 = load_data('./final-csv/hot-100')  # adjust path as needed\n",
    "global200 = load_data('./final-csv/global-200')  # adjust path as needed\n",
    "\n",
    "# Helper functions (use your regex-based ones)\n",
    "def is_korean(word):\n",
    "    return bool(re.search(r'[\\uac00-\\ud7af]', word))\n",
    "\n",
    "def is_english(word):\n",
    "    return bool(re.search(r'[a-zA-Z]', word))\n",
    "\n",
    "def get_korean_ratio(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text))\n",
    "    if not words:\n",
    "        return 0\n",
    "    korean_count = sum(1 for w in words if is_korean(w))\n",
    "    return korean_count / len(words)\n",
    "\n",
    "def get_english_ratio(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text))\n",
    "    if not words:\n",
    "        return 0\n",
    "    english_count = sum(1 for w in words if is_english(w))\n",
    "    return english_count / len(words)\n",
    "\n",
    "def count_filler_words(text, filler_words):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
    "    return sum(1 for w in words if w in filler_words)\n",
    "import re\n",
    "\n",
    "def is_korean(word):\n",
    "    return bool(re.search(r'[\\uac00-\\ud7af]', word))\n",
    "\n",
    "def is_english(word):\n",
    "    return bool(re.search(r'[a-zA-Z]', word))\n",
    "\n",
    "def classify_word_regex(word):\n",
    "    if is_korean(word):\n",
    "        return 'KOREAN'\n",
    "    elif is_english(word):\n",
    "        return 'ENGLISH'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "def count_word_level_language_switches(text):\n",
    "    words = re.findall(r'\\b\\w+\\b', str(text))\n",
    "    langs = [classify_word_regex(w) for w in words if classify_word_regex(w) in ['KOREAN', 'ENGLISH']]\n",
    "    return sum(1 for i in range(len(langs)-1) if langs[i] != langs[i+1])\n",
    "\n",
    "# Alliteration (English only, as before)\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "cmu_dict = cmudict.dict()\n",
    "def get_first_phoneme(word):\n",
    "    word = word.lower()\n",
    "    if word in cmu_dict:\n",
    "        return cmu_dict[word][0][0]\n",
    "    return None\n",
    "def count_alliterations(text):\n",
    "    words = nltk.word_tokenize(str(text))\n",
    "    phonemes = [get_first_phoneme(word) for word in words]\n",
    "    filtered = [ph for ph in phonemes if ph is not None]\n",
    "    count = 0\n",
    "    for i in range(len(filtered)-1):\n",
    "        if filtered[i] == filtered[i+1]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Repetitions (word/phrase/sentence)\n",
    "def count_consecutive_repetitions(text, max_ngram=5):\n",
    "    tokens = str(text).split()\n",
    "    total_rep = 0\n",
    "    rep_dict = {}\n",
    "    i = 0\n",
    "    n_tokens = len(tokens)\n",
    "    while i < n_tokens:\n",
    "        found_repeat = False\n",
    "        for n in range(max_ngram, 0, -1):\n",
    "            if i + n > n_tokens:\n",
    "                continue\n",
    "            current_ngram = tokens[i:i+n]\n",
    "            rep_count = 0\n",
    "            j = i + n\n",
    "            while j + n <= n_tokens and tokens[j:j+n] == current_ngram:\n",
    "                rep_count += 1\n",
    "                j += n\n",
    "            if rep_count > 0:\n",
    "                phrase = \" \".join(current_ngram)\n",
    "                total_rep += rep_count\n",
    "                rep_dict[phrase] = rep_dict.get(phrase, 0) + rep_count\n",
    "                i = j\n",
    "                found_repeat = True\n",
    "                break\n",
    "        if not found_repeat:\n",
    "            i += 1\n",
    "    # Sentence-level\n",
    "    sentences = sent_tokenize(str(text))\n",
    "    i = 0\n",
    "    n_sent = len(sentences)\n",
    "    while i < n_sent - 1:\n",
    "        rep_count = 0\n",
    "        j = i + 1\n",
    "        while j < n_sent and sentences[j].strip() == sentences[i].strip():\n",
    "            rep_count += 1\n",
    "            j += 1\n",
    "        if rep_count > 0:\n",
    "            phrase = sentences[i].strip()\n",
    "            total_rep += rep_count\n",
    "            rep_dict[phrase] = rep_dict.get(phrase, 0) + rep_count\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "    return total_rep, rep_dict\n",
    "\n",
    "def count_repetitions(text):\n",
    "    return count_consecutive_repetitions(text, max_ngram=5)\n",
    "\n",
    "# Filler words list (customize as needed)\n",
    "filler_words = []\n",
    "with open(\"./filler.txt\", \"r\") as f:\n",
    "    # if the element is \"\", it will be skipped\n",
    "    for line in f:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        # print(line)\n",
    "        filler_words.append(line.strip())\n",
    "filler_words.sort()\n",
    "\n",
    "# Apply features\n",
    "for df in [hot100, global200]:\n",
    "    df['kor_ratio'] = df['Cleaned Lyrics'].fillna('').apply(get_korean_ratio)\n",
    "    df['eng_ratio'] = df['Cleaned Lyrics'].fillna('').apply(get_english_ratio)\n",
    "    df['filler_count'] = df['Cleaned Lyrics'].fillna('').apply(lambda x: count_filler_words(x, filler_words))\n",
    "    df['alliteration_count'] = df['Cleaned Lyrics'].fillna('').apply(count_alliterations)\n",
    "    df['repetition_count'], df['repetition_dict'] = zip(*df['Cleaned Lyrics'].fillna('').apply(count_repetitions))\n",
    "    df['Gender_enc'] = np.where(df['Gender'] == 'F', 1, 0)\n",
    "    df['Category_enc'] = np.where(df['Category'] == 'S', 1, 0)\n",
    "    df['code_switches'] = df['Cleaned Lyrics'].fillna('').apply(count_word_level_language_switches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using `xlm-roberta-base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot 100 Classification with Multiple Models:\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.69      0.90      0.78        10\n",
      "        Girl       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.72      0.66      0.66        17\n",
      "weighted avg       0.72      0.71      0.68        17\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.62      0.80      0.70        10\n",
      "        Girl       0.50      0.29      0.36         7\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.56      0.54      0.53        17\n",
      "weighted avg       0.57      0.59      0.56        17\n",
      "\n",
      "\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.54      0.70      0.61        10\n",
      "        Girl       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.47        17\n",
      "   macro avg       0.39      0.42      0.40        17\n",
      "weighted avg       0.42      0.47      0.43        17\n",
      "\n",
      "\n",
      "MLP (Neural Net)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.60      0.60      0.60        10\n",
      "        Girl       0.43      0.43      0.43         7\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.51      0.51      0.51        17\n",
      "weighted avg       0.53      0.53      0.53        17\n",
      "\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.60      0.90      0.72        10\n",
      "        Girl       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.55      0.52      0.47        17\n",
      "weighted avg       0.56      0.59      0.52        17\n",
      "\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.69      0.90      0.78        10\n",
      "        Girl       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.72      0.66      0.66        17\n",
      "weighted avg       0.72      0.71      0.68        17\n",
      "\n",
      "Best model for Hot 100: Logistic Regression (Macro F1: 0.664)\n",
      "\n",
      "Global 200 Classification with Multiple Models:\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.69      0.53      0.60        17\n",
      "        Girl       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.70      0.68      0.68        40\n",
      "weighted avg       0.70      0.70      0.69        40\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.67      0.47      0.55        17\n",
      "        Girl       0.68      0.83      0.75        23\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.67      0.65      0.65        40\n",
      "weighted avg       0.67      0.68      0.66        40\n",
      "\n",
      "\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.44      0.41      0.42        17\n",
      "        Girl       0.58      0.61      0.60        23\n",
      "\n",
      "    accuracy                           0.53        40\n",
      "   macro avg       0.51      0.51      0.51        40\n",
      "weighted avg       0.52      0.53      0.52        40\n",
      "\n",
      "\n",
      "MLP (Neural Net)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.54      0.41      0.47        17\n",
      "        Girl       0.63      0.74      0.68        23\n",
      "\n",
      "    accuracy                           0.60        40\n",
      "   macro avg       0.58      0.58      0.57        40\n",
      "weighted avg       0.59      0.60      0.59        40\n",
      "\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.60      0.35      0.44        17\n",
      "        Girl       0.63      0.83      0.72        23\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.62      0.59      0.58        40\n",
      "weighted avg       0.62      0.62      0.60        40\n",
      "\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.56      0.53      0.55        17\n",
      "        Girl       0.67      0.70      0.68        23\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.61      0.61      0.61        40\n",
      "weighted avg       0.62      0.62      0.62        40\n",
      "\n",
      "Best model for Global 200: Logistic Regression (Macro F1: 0.680)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_lyrics_features(X):\n",
    "    # get embeddings from xlm-roberta-base\n",
    "    tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "    model = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "    embeddings = []\n",
    "    for lyrics in X:\n",
    "        inputs = tokenizer(lyrics, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def run_multiple_classifiers(X, y, indices, target_names=['Boy', 'Girl']):\n",
    "    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, indices, stratify=y, random_state=42)\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"MLP (Neural Net)\": MLPClassifier(max_iter=500),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"Voting Classifier\": VotingClassifier(\n",
    "            estimators=[('lr', LogisticRegression(max_iter=1000)),\n",
    "                        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "                        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "                        ('mlp', MLPClassifier(max_iter=500))],\n",
    "            voting='soft'\n",
    "        )\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        print(f\"\\n{name}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'y_pred': y_pred,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'idx_test': idx_test,\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': macro_f1\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Prepare your features as before\n",
    "def prepare_features(df, features=None):\n",
    "    if features is None:\n",
    "        features = ['kor_ratio', 'eng_ratio', 'filler_count', 'alliteration_count', 'repetition_count', 'code_switches']\n",
    "    X = df[features]\n",
    "    X_lyrics = get_lyrics_features(df['Cleaned Lyrics'])\n",
    "    X_pca = PCA(n_components=30).fit_transform(X_lyrics)\n",
    "    X = np.concatenate([X, X_pca], axis=1)\n",
    "    y = df['Gender_enc']\n",
    "    indices = df.index\n",
    "    return X, y, indices\n",
    "\n",
    "print(\"Hot 100 Classification with Multiple Models:\")\n",
    "X_hot, y_hot, indices_hot = prepare_features(hot100)\n",
    "hot100_results = run_multiple_classifiers(X_hot, y_hot, indices_hot)\n",
    "best_model_name_100 = max(hot100_results, key=lambda k: hot100_results[k]['macro_f1'])\n",
    "print(f\"Best model for Hot 100: {best_model_name_100} (Macro F1: {hot100_results[best_model_name_100]['macro_f1']:.3f})\")\n",
    "\n",
    "print(\"\\nGlobal 200 Classification with Multiple Models:\")\n",
    "X_global, y_global, indices_global = prepare_features(global200)\n",
    "global200_results = run_multiple_classifiers(X_global, y_global, indices_global)\n",
    "best_model_name_200 = max(global200_results, key=lambda k: global200_results[k]['macro_f1'])\n",
    "print(f\"Best model for Global 200: {best_model_name_200} (Macro F1: {global200_results[best_model_name_200]['macro_f1']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassification analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_misclassifications(df, test_idx, y_test, y_pred):\n",
    "    df_test = df.loc[test_idx].copy()\n",
    "    df_test['true_label'] = y_test\n",
    "    df_test['pred_label'] = y_pred\n",
    "    false_pos = df_test[(df_test['true_label'] == 0) & (df_test['pred_label'] == 1)]\n",
    "    false_neg = df_test[(df_test['true_label'] == 1) & (df_test['pred_label'] == 0)]\n",
    "    print(f\"False Positives (Boy predicted as Girl): {len(false_pos)}\")\n",
    "    print(false_pos[['artist', 'title', 'Cleaned Lyrics']].head())\n",
    "    print(f\"\\nFalse Negatives (Girl predicted as Boy): {len(false_neg)}\")\n",
    "    print(false_neg[['artist', 'title', 'Cleaned Lyrics']].head())\n",
    "    return false_pos, false_neg\n",
    "\n",
    "print(\"Hot 100 Misclassifications:\")\n",
    "hot100_fp, hot100_fn = analyze_misclassifications(\n",
    "    hot100, \n",
    "    hot100_results[best_model_name_100]['idx_test'],  # pass indices, not X_test\n",
    "    hot100_results[best_model_name_100]['y_test'],\n",
    "    hot100_results[best_model_name_100]['y_pred']\n",
    ")\n",
    "print(\"\\nGlobal 200 Misclassifications:\")\n",
    "global200_fp, global200_fn = analyze_misclassifications(\n",
    "    global200,\n",
    "    global200_results[best_model_name_200]['idx_test'],  # pass indices, not X_test\n",
    "    global200_results[best_model_name_200]['y_test'],\n",
    "    global200_results[best_model_name_200]['y_pred']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using `gte-multilingual-base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot 100 Classification with Multiple Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.75      0.60      0.67        10\n",
      "        Girl       0.56      0.71      0.62         7\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.65      0.66      0.65        17\n",
      "weighted avg       0.67      0.65      0.65        17\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.69      0.90      0.78        10\n",
      "        Girl       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.72      0.66      0.66        17\n",
      "weighted avg       0.72      0.71      0.68        17\n",
      "\n",
      "\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.70      0.70      0.70        10\n",
      "        Girl       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.64      0.64      0.64        17\n",
      "weighted avg       0.65      0.65      0.65        17\n",
      "\n",
      "\n",
      "MLP (Neural Net)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.78      0.70      0.74        10\n",
      "        Girl       0.62      0.71      0.67         7\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.70      0.71      0.70        17\n",
      "weighted avg       0.71      0.71      0.71        17\n",
      "\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.60      0.90      0.72        10\n",
      "        Girl       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.59        17\n",
      "   macro avg       0.55      0.52      0.47        17\n",
      "weighted avg       0.56      0.59      0.52        17\n",
      "\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.88      0.70      0.78        10\n",
      "        Girl       0.67      0.86      0.75         7\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.77      0.78      0.76        17\n",
      "weighted avg       0.79      0.76      0.77        17\n",
      "\n",
      "Best model for Hot 100: Voting Classifier (Macro F1: 0.764)\n",
      "\n",
      "Global 200 Classification with Multiple Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.71      0.59      0.65        17\n",
      "        Girl       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.72        40\n",
      "   macro avg       0.72      0.71      0.71        40\n",
      "weighted avg       0.72      0.72      0.72        40\n",
      "\n",
      "\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.73      0.47      0.57        17\n",
      "        Girl       0.69      0.87      0.77        23\n",
      "\n",
      "    accuracy                           0.70        40\n",
      "   macro avg       0.71      0.67      0.67        40\n",
      "weighted avg       0.71      0.70      0.69        40\n",
      "\n",
      "\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.61      0.65      0.63        17\n",
      "        Girl       0.73      0.70      0.71        23\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.67      0.67      0.67        40\n",
      "weighted avg       0.68      0.68      0.68        40\n",
      "\n",
      "\n",
      "MLP (Neural Net)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.62      0.47      0.53        17\n",
      "        Girl       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.64      0.63      0.63        40\n",
      "weighted avg       0.64      0.65      0.64        40\n",
      "\n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.60      0.35      0.44        17\n",
      "        Girl       0.63      0.83      0.72        23\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.62      0.59      0.58        40\n",
      "weighted avg       0.62      0.62      0.60        40\n",
      "\n",
      "\n",
      "Voting Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Boy       0.75      0.53      0.62        17\n",
      "        Girl       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.72        40\n",
      "   macro avg       0.73      0.70      0.70        40\n",
      "weighted avg       0.73      0.72      0.71        40\n",
      "\n",
      "Best model for Global 200: Logistic Regression (Macro F1: 0.710)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_lyrics_features(X):\n",
    "    # get embeddings from xlm-roberta-base\n",
    "    tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-multilingual-base', trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained('Alibaba-NLP/gte-multilingual-base', trust_remote_code=True)\n",
    "    embeddings = []\n",
    "    for lyrics in X:\n",
    "        inputs = tokenizer(lyrics, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def run_multiple_classifiers(X, y, indices, target_names=['Boy', 'Girl']):\n",
    "    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, indices, stratify=y, random_state=42)\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        \"MLP (Neural Net)\": MLPClassifier(max_iter=500),\n",
    "        \"SVM\": SVC(probability=True),\n",
    "        \"Voting Classifier\": VotingClassifier(\n",
    "            estimators=[('lr', LogisticRegression(max_iter=1000)),\n",
    "                        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "                        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "                        ('mlp', MLPClassifier(max_iter=500))],\n",
    "            voting='soft'\n",
    "        )\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        print(f\"\\n{name}\")\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'y_pred': y_pred,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'idx_test': idx_test,\n",
    "            'accuracy': acc,\n",
    "            'macro_f1': macro_f1\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Prepare your features as before\n",
    "def prepare_features(df, features=None):\n",
    "    if features is None:\n",
    "        features = ['kor_ratio', 'eng_ratio', 'filler_count', 'alliteration_count', 'repetition_count', 'code_switches']\n",
    "    X = df[features]\n",
    "    X_lyrics = get_lyrics_features(df['Cleaned Lyrics'])\n",
    "    X_pca = PCA(n_components=30).fit_transform(X_lyrics)\n",
    "    X = np.concatenate([X, X_pca], axis=1)\n",
    "    y = df['Gender_enc']\n",
    "    indices = df.index\n",
    "    return X, y, indices\n",
    "\n",
    "print(\"Hot 100 Classification with Multiple Models:\")\n",
    "X_hot, y_hot, indices_hot = prepare_features(hot100)\n",
    "hot100_results = run_multiple_classifiers(X_hot, y_hot, indices_hot)\n",
    "best_model_name_100 = max(hot100_results, key=lambda k: hot100_results[k]['macro_f1'])\n",
    "print(f\"Best model for Hot 100: {best_model_name_100} (Macro F1: {hot100_results[best_model_name_100]['macro_f1']:.3f})\")\n",
    "\n",
    "print(\"\\nGlobal 200 Classification with Multiple Models:\")\n",
    "X_global, y_global, indices_global = prepare_features(global200)\n",
    "global200_results = run_multiple_classifiers(X_global, y_global, indices_global)\n",
    "best_model_name_200 = max(global200_results, key=lambda k: global200_results[k]['macro_f1'])\n",
    "print(f\"Best model for Global 200: {best_model_name_200} (Macro F1: {global200_results[best_model_name_200]['macro_f1']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot 100 Misclassifications:\n",
      "False Positives (Boy predicted as Girl): 3\n",
      "    artist                title  \\\n",
      "14     bts            fake love   \n",
      "30  j-hope  chicken noodle soup   \n",
      "7        v        love me again   \n",
      "\n",
      "                                       Cleaned Lyrics  \n",
      "14  널 위해서라면 난\\n슬퍼도 기쁜 척 할 수가 있었어\\n널 위해서라면 난\\n아파도 강...  \n",
      "30  Chicken noodle soup\\nChicken noodle soup\\nChic...  \n",
      "7   추억도 의미 없이\\n내게 넌 사라지고\\n이쯤에도 I can't let you go,...  \n",
      "\n",
      "False Negatives (Girl predicted as Boy): 1\n",
      "         artist title                                     Cleaned Lyrics\n",
      "35  le sserafim  easy  다친대도, 길을 걸어, kiss me\\n쉽지 않음 내가 쉽게 easy\\nStage,...\n",
      "\n",
      "Global 200 Misclassifications:\n",
      "False Positives (Boy predicted as Girl): 7\n",
      "         artist         title  \\\n",
      "52   stray kids  chk chk boom   \n",
      "18            v     fri(end)s   \n",
      "122     enhypen   sweet venom   \n",
      "53   stray kids        maniac   \n",
      "10    jung kook      hate you   \n",
      "\n",
      "                                        Cleaned Lyrics  \n",
      "52   Boom, boom, chk, chk, boom\\n(Brrah) 정중앙 흑색의 저 ...  \n",
      "18   You're in my head\\nI had plans for the weekend...  \n",
      "122  Yeah\\nOh-oh\\nHey, 내 안에 번져가는 something\\n감미롭게 나를...  \n",
      "53   Let's go\\n정상인 척 다들 힘 좀 빼\\n짓고 있는 미소들은 쎄해\\nLock이...  \n",
      "10   So, I'm gonna hate you\\nI'm gonna hate you\\nPa...  \n",
      "\n",
      "False Negatives (Girl predicted as Boy): 4\n",
      "        artist      title                                     Cleaned Lyrics\n",
      "136   newjeans     get up  35 ContributorsTranslationsTürkçeEspañolPortug...\n",
      "150       rose       apt.  아파트, 아파트\\n아파트, 아파트\\n아파트, 아파트\\nUh, uh-huh, uh-h...\n",
      "66       twice  the feels  Boy, I, boy, I, boy, I know\\nI know you get th...\n",
      "100  blackpink  ice cream  Come a little closer 'cause you lookin' thirst...\n"
     ]
    }
   ],
   "source": [
    "def analyze_misclassifications(df, test_idx, y_test, y_pred):\n",
    "    df_test = df.loc[test_idx].copy()\n",
    "    df_test['true_label'] = y_test\n",
    "    df_test['pred_label'] = y_pred\n",
    "    false_pos = df_test[(df_test['true_label'] == 0) & (df_test['pred_label'] == 1)]\n",
    "    false_neg = df_test[(df_test['true_label'] == 1) & (df_test['pred_label'] == 0)]\n",
    "    print(f\"False Positives (Boy predicted as Girl): {len(false_pos)}\")\n",
    "    print(false_pos[['artist', 'title', 'Cleaned Lyrics']].head())\n",
    "    print(f\"\\nFalse Negatives (Girl predicted as Boy): {len(false_neg)}\")\n",
    "    print(false_neg[['artist', 'title', 'Cleaned Lyrics']].head())\n",
    "    return false_pos, false_neg\n",
    "\n",
    "print(\"Hot 100 Misclassifications:\")\n",
    "hot100_fp, hot100_fn = analyze_misclassifications(\n",
    "    hot100, \n",
    "    hot100_results[best_model_name_100]['idx_test'],  # pass indices, not X_test\n",
    "    hot100_results[best_model_name_100]['y_test'],\n",
    "    hot100_results[best_model_name_100]['y_pred']\n",
    ")\n",
    "print(\"\\nGlobal 200 Misclassifications:\")\n",
    "global200_fp, global200_fn = analyze_misclassifications(\n",
    "    global200,\n",
    "    global200_results[best_model_name_200]['idx_test'],  # pass indices, not X_test\n",
    "    global200_results[best_model_name_200]['y_test'],\n",
    "    global200_results[best_model_name_200]['y_pred']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio analysis in lyrics\n",
    "- Analyzing the ratio of Korean and English words in the lyrics of hot-100.\n",
    "- Analyzing the ratio of Korean and English words in the lyrics of global-200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot 100 Group/Solo & Gender Stats:\n",
      "                 kor_ratio  eng_ratio\n",
      "Category Gender                      \n",
      "G        F        0.177550   0.822619\n",
      "         M        0.357985   0.617417\n",
      "S        F        0.035586   0.963222\n",
      "         M        0.106725   0.893128\n",
      "\n",
      "Most common bigrams for G F:\n",
      "[('I know', 35), ('on my', 27), ('I, boy,', 24), ('I got', 24), ('it, whip', 24), ('All the', 21), ('all the', 20), ('you like', 19), ('Moonlight sunrise', 17), ('make you', 17)]\n",
      "\n",
      "Most common bigrams for G M:\n",
      "[('I know', 19), ('Oh, oh,', 18), ('make it', 17), ('bring the', 16), ('in the', 15), ('I can', 15), ('fake love,', 14), ('love, fake', 14), ('me now', 14), ('yeah, yeah,', 14)]\n",
      "\n",
      "Most common bigrams for S F:\n",
      "[('아파트, 아파트', 30), ('ladies run', 23), (\"I'm a\", 21), ('JENNIE, JENNIE,', 20), ('on the', 20), ('아파트 아파트,', 20), ('be born', 18), ('my ladies', 15), ('call me', 15), ('the ground', 14)]\n",
      "\n",
      "Most common bigrams for S M:\n",
      "[('go, go,', 50), ('Chicken noodle', 30), ('noodle soup', 30), ('I like', 24), ('Never let', 23), ('love me', 21), ('next to', 20), ('let go,', 20), ('go, go', 20), ('soup Chicken', 20)]\n",
      "\n",
      "Global 200 Group/Solo & Gender Stats:\n",
      "                 kor_ratio  eng_ratio\n",
      "Category Gender                      \n",
      "G        F        0.223105   0.774805\n",
      "         M        0.334350   0.649294\n",
      "S        F        0.048092   0.951133\n",
      "         M        0.170988   0.828999\n",
      "\n",
      "Most common bigrams for G F:\n",
      "[('tok, tik,', 138), ('tik, tok,', 92), ('I know', 56), ('I got', 49), ('in the', 46), ('tik, tik,', 46), (\"I don't\", 39), ('on my', 37), (\"I'm a\", 36), ('with my', 35)]\n",
      "\n",
      "Most common bigrams for G M:\n",
      "[('get it', 20), ('I know', 19), ('hot, hot,', 19), ('it done,', 18), ('in the', 17), ('I wanna', 15), ('you know', 14), ('hot, hot', 13), ('I got', 13), (\"I'm a\", 12)]\n",
      "\n",
      "Most common bigrams for S F:\n",
      "[('break, break,', 36), ('아파트, 아파트', 30), ('in the', 28), ('to be', 28), ('I did', 27), ('on the', 26), ('I need', 24), ('ladies run', 23), ('Damn, right,', 23), ('I just', 22)]\n",
      "\n",
      "Most common bigrams for S M:\n",
      "[('go, go,', 50), ('to be', 36), ('I want', 35), ('Never let', 31), ('in the', 27), ('let you', 26), ('you to', 25), ('you know', 24), ('I like', 24), ('want you', 24)]\n"
     ]
    }
   ],
   "source": [
    "def group_phrase_stats(df, group_col='Category', gender_col='Gender'):\n",
    "    # Korean/English ratio\n",
    "    print(df.groupby([group_col, gender_col])[['kor_ratio', 'eng_ratio']].mean())\n",
    "    # Most common phrases (bigrams)\n",
    "    for (g, gender), group_df in df.groupby([group_col, gender_col]):\n",
    "        all_lyrics = ' '.join(group_df['Cleaned Lyrics'].dropna())\n",
    "        bigrams = [' '.join(pair) for pair in zip(all_lyrics.split()[:-1], all_lyrics.split()[1:])]\n",
    "        bigram_counts = Counter(bigrams)\n",
    "        print(f\"\\nMost common bigrams for {g} {gender}:\")\n",
    "        print(bigram_counts.most_common(10))\n",
    "\n",
    "print(\"Hot 100 Group/Solo & Gender Stats:\")\n",
    "group_phrase_stats(hot100)\n",
    "print(\"\\nGlobal 200 Group/Solo & Gender Stats:\")\n",
    "group_phrase_stats(global200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "- Using statistical analysis to analyze the data.\n",
    "- Using t-test to analyze the data.\n",
    "- Using Mann-Whitney U test to analyze the data.\n",
    "- Using Shapiro-Wilk test to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing feature: code_switches\n",
      "Group 0 mean: 19.05\n",
      "Group 1 mean: 16.96\n",
      "Welch t-test: t-statistic: 0.41, p-value: 0.6862\n",
      "Group 0 normality p-value: 0.0001\n",
      "Group 1 normality p-value: 0.0002\n",
      "Mann-Whitney U statistic: 555.50, p-value: 0.6109\n",
      "\n",
      "Analyzing feature: kor_ratio\n",
      "Group 0 mean: 0.24\n",
      "Group 1 mean: 0.11\n",
      "Welch t-test: t-statistic: 2.68, p-value: 0.0097\n",
      "Group 0 normality p-value: 0.0002\n",
      "Group 1 normality p-value: 0.0006\n",
      "Mann-Whitney U statistic: 646.00, p-value: 0.0796\n"
     ]
    }
   ],
   "source": [
    "# Do boy groups and girl groups differ in the amount of code-switching in their lyrics?\n",
    "# Do boy groups and girl groups differ in the proportion of Korean lyrics in their songs?\n",
    "\n",
    "from scipy.stats import ttest_ind, shapiro, mannwhitneyu\n",
    "\n",
    "def run_statistical_analysis(df, feature, group_col='Gender_enc'):\n",
    "    group0 = df[df[group_col] == 0][feature].dropna()\n",
    "    group1 = df[df[group_col] == 1][feature].dropna()\n",
    "    print(f\"\\nAnalyzing feature: {feature}\")\n",
    "    print(f\"Group 0 mean: {group0.mean():.2f}\")\n",
    "    print(f\"Group 1 mean: {group1.mean():.2f}\")\n",
    "    # Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(group0, group1, equal_var=False)\n",
    "    print(f\"Welch t-test: t-statistic: {t_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "    # Shapiro-Wilk normality test\n",
    "    stat0, p0 = shapiro(group0)\n",
    "    stat1, p1 = shapiro(group1)\n",
    "    print(f\"Group 0 normality p-value: {p0:.4f}\")\n",
    "    print(f\"Group 1 normality p-value: {p1:.4f}\")\n",
    "    # Mann-Whitney U test\n",
    "    u_stat, p_u = mannwhitneyu(group0, group1, alternative='two-sided')\n",
    "    print(f\"Mann-Whitney U statistic: {u_stat:.2f}, p-value: {p_u:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "run_statistical_analysis(hot100, 'code_switches')\n",
    "run_statistical_analysis(hot100, 'kor_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing feature: code_switches\n",
      "Group 0 mean: 20.57\n",
      "Group 1 mean: 25.32\n",
      "Welch t-test: t-statistic: -1.20, p-value: 0.2312\n",
      "Group 0 normality p-value: 0.0000\n",
      "Group 1 normality p-value: 0.0000\n",
      "Mann-Whitney U statistic: 2960.50, p-value: 0.6341\n",
      "\n",
      "Analyzing feature: kor_ratio\n",
      "Group 0 mean: 0.24\n",
      "Group 1 mean: 0.17\n",
      "Welch t-test: t-statistic: 1.93, p-value: 0.0558\n",
      "Group 0 normality p-value: 0.0000\n",
      "Group 1 normality p-value: 0.0000\n",
      "Mann-Whitney U statistic: 3547.00, p-value: 0.1054\n"
     ]
    }
   ],
   "source": [
    "# Do boy groups and girl groups differ in the amount of code-switching in their lyrics?\n",
    "# Do boy groups and girl groups differ in the proportion of Korean lyrics in their songs?\n",
    "\n",
    "from scipy.stats import ttest_ind, shapiro, mannwhitneyu\n",
    "\n",
    "def run_statistical_analysis(df, feature, group_col='Gender_enc'):\n",
    "    group0 = df[df[group_col] == 0][feature].dropna()\n",
    "    group1 = df[df[group_col] == 1][feature].dropna()\n",
    "    print(f\"\\nAnalyzing feature: {feature}\")\n",
    "    print(f\"Group 0 mean: {group0.mean():.2f}\")\n",
    "    print(f\"Group 1 mean: {group1.mean():.2f}\")\n",
    "    # Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(group0, group1, equal_var=False)\n",
    "    print(f\"Welch t-test: t-statistic: {t_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "    # Shapiro-Wilk normality test\n",
    "    stat0, p0 = shapiro(group0)\n",
    "    stat1, p1 = shapiro(group1)\n",
    "    print(f\"Group 0 normality p-value: {p0:.4f}\")\n",
    "    print(f\"Group 1 normality p-value: {p1:.4f}\")\n",
    "    # Mann-Whitney U test\n",
    "    u_stat, p_u = mannwhitneyu(group0, group1, alternative='two-sided')\n",
    "    print(f\"Mann-Whitney U statistic: {u_stat:.2f}, p-value: {p_u:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "run_statistical_analysis(global200, 'code_switches')\n",
    "run_statistical_analysis(global200, 'kor_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RQ1:** Do boy groups and girl groups differ in the amount of code-switching in their lyrics?\n",
    "- **RQ2:** Do boy groups and girl groups differ in the proportion of Korean lyrics in their songs?\n",
    "\n",
    "\n",
    "## **Summary of Results**\n",
    "\n",
    "### **A. Code-Switching**\n",
    "\n",
    "- **Means:**  \n",
    "  - Boy groups: 19.05  \n",
    "  - Girl groups: 16.96\n",
    "- **Welch’s t-test:**  \n",
    "  - t = 0.41, p = 0.6862\n",
    "- **Shapiro-Wilk normality:**  \n",
    "  - Both p < 0.001 (not normal)\n",
    "- **Mann-Whitney U test:**  \n",
    "  - U = 555.50, p = 0.6109\n",
    "\n",
    "**Interpretation:**  \n",
    "- The mean code-switching count is slightly higher for boy groups, but the difference is **not statistically significant** (p > 0.05) in both the t-test and the Mann-Whitney U test.\n",
    "- The distributions are not normal, so the Mann-Whitney U test is more reliable.\n",
    "- **Conclusion:** We fail to reject the null hypothesis; there is no significant difference in code-switching frequency between boy and girl groups.\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Korean Lyric Ratio**\n",
    "\n",
    "- **Means:**  \n",
    "  - Boy groups: 0.24  \n",
    "  - Girl groups: 0.11\n",
    "- **Welch’s t-test:**  \n",
    "  - t = 2.68, p = 0.0097\n",
    "- **Shapiro-Wilk normality:**  \n",
    "  - Both p < 0.001 (not normal)\n",
    "- **Mann-Whitney U test:**  \n",
    "  - U = 646.00, p = 0.0796\n",
    "\n",
    "**Interpretation:**  \n",
    "- The mean Korean lyric ratio is higher for boy groups (0.24) than for girl groups (0.11).\n",
    "- The t-test suggests a significant difference (p = 0.0097), but the data are not normal.\n",
    "- The Mann-Whitney U test, which is more appropriate here, gives p = 0.0796 (**not significant at the 0.05 level**).\n",
    "- **Conclusion:** We fail to reject the null hypothesis; there is no statistically significant difference in the proportion of Korean lyrics between boy and girl groups, although the difference is numerically notable and approaches significance.\n",
    "\n",
    "---\n",
    "\n",
    "### How i might write this in the paper\n",
    "\n",
    "We compared both the frequency of code-switching and the proportion of Korean lyrics between boy and girl groups in Hot 100 songs. The mean code-switching count was 19.05 for boy groups and 16.96 for girl groups, while the mean Korean lyric ratio was 0.24 for boy groups and 0.11 for girl groups. Welch’s t-test suggested a significant difference in Korean lyric ratio (t = 2.68, p = 0.0097), but not in code-switching (t = 0.41, p = 0.6862). However, the Shapiro-Wilk test indicated that the distributions of both features were not normal (p < 0.001 for all groups). Therefore, we relied on the non-parametric Mann-Whitney U test, which found no significant difference for either code-switching (U = 555.50, p = 0.6109) or Korean lyric ratio (U = 646.00, p = 0.0796). Thus, we fail to reject the null hypothesis and conclude that there is no statistically significant difference between boy and girl groups in either code-switching frequency or the proportion of Korean lyrics in Hot 100 songs, although the difference in Korean lyric ratio approaches significance.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- **Statistical best practice:** When normality is violated, non-parametric tests are preferred.\n",
    "- **\"Fail to reject the null hypothesis\":** This is the correct language when p > 0.05.\n",
    "- **Reporting means:** Shows the numerical trend, even if not statistically significant.\n",
    "- **Reporting both tests:** Demonstrates rigor and transparency.\n",
    "\n",
    "\n",
    "\"The difference in Korean lyric ratio approaches statistical significance (p = 0.0796), suggesting a possible trend for boy groups to use more Korean lyrics than girl groups, but this did not reach the conventional threshold for significance.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boy groups:\n",
      "  Hot 100 mean kor_ratio: 0.236\n",
      "  Global 200 mean kor_ratio: 0.238\n",
      "  Welch t-test: t-statistic: -0.05, p-value: 0.9599\n",
      "  Hot 100 normality p-value: 0.0002\n",
      "  Global 200 normality p-value: 0.0000\n",
      "  Mann-Whitney U statistic: 1234.00, p-value: 0.8717\n",
      "\n",
      "Girl groups:\n",
      "  Hot 100 mean kor_ratio: 0.112\n",
      "  Global 200 mean kor_ratio: 0.171\n",
      "  Welch t-test: t-statistic: -2.00, p-value: 0.0498\n",
      "  Hot 100 normality p-value: 0.0006\n",
      "  Global 200 normality p-value: 0.0000\n",
      "  Mann-Whitney U statistic: 1076.00, p-value: 0.1995\n"
     ]
    }
   ],
   "source": [
    "# Is there a difference in the proportion of Korean lyrics (kor_ratio) between Hot 100 and Global 200 charts for boy and girl groups?\n",
    "from scipy.stats import ttest_ind, shapiro, mannwhitneyu\n",
    "\n",
    "def compare_kor_ratio_between_charts(hot100, global200, gender_enc, gender_label):\n",
    "    # Filter by gender\n",
    "    hot_kor = hot100[hot100['Gender_enc'] == gender_enc]['kor_ratio'].dropna()\n",
    "    global_kor = global200[global200['Gender_enc'] == gender_enc]['kor_ratio'].dropna()\n",
    "    print(f\"\\n{gender_label} groups:\")\n",
    "    print(f\"  Hot 100 mean kor_ratio: {hot_kor.mean():.3f}\")\n",
    "    print(f\"  Global 200 mean kor_ratio: {global_kor.mean():.3f}\")\n",
    "    # Welch's t-test\n",
    "    t_stat, p_val = ttest_ind(hot_kor, global_kor, equal_var=False)\n",
    "    print(f\"  Welch t-test: t-statistic: {t_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "    # Shapiro-Wilk normality\n",
    "    p_hot = shapiro(hot_kor)[1]\n",
    "    p_global = shapiro(global_kor)[1]\n",
    "    print(f\"  Hot 100 normality p-value: {p_hot:.4f}\")\n",
    "    print(f\"  Global 200 normality p-value: {p_global:.4f}\")\n",
    "    # Mann-Whitney U test\n",
    "    u_stat, p_u = mannwhitneyu(hot_kor, global_kor, alternative='two-sided')\n",
    "    print(f\"  Mann-Whitney U statistic: {u_stat:.2f}, p-value: {p_u:.4f}\")\n",
    "\n",
    "# Run for both genders\n",
    "compare_kor_ratio_between_charts(hot100, global200, gender_enc=0, gender_label=\"Boy\")\n",
    "compare_kor_ratio_between_charts(hot100, global200, gender_enc=1, gender_label=\"Girl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question:\n",
    "- Is there a difference in the proportion of Korean lyrics (kor_ratio) between Hot 100 and Global 200 charts for boy and girl groups?\n",
    "\n",
    "Hypotheses (for each gender):\n",
    "- Null hypothesis (H₀):\n",
    "    The mean Korean lyric ratio is the same for Hot 100 and Global 200 songs.\n",
    "    (μ_hot100 = μ_global200)\n",
    "- Alternative hypothesis (H₁):\n",
    "    The mean Korean lyric ratio is different between Hot 100 and Global 200 songs.\n",
    "    (μ_hot100 ≠ μ_global200)\n",
    "--\n",
    "\n",
    "### **A. Boy Groups**\n",
    "\n",
    "- **Hot 100 mean kor_ratio:** 0.236  \n",
    "- **Global 200 mean kor_ratio:** 0.238  \n",
    "- **Welch’s t-test:** t = -0.05, p = 0.9599  \n",
    "- **Shapiro-Wilk normality:** Both p < 0.001 (not normal)\n",
    "- **Mann-Whitney U test:** U = 1234.00, p = 0.8717\n",
    "\n",
    "**Interpretation:**  \n",
    "- The mean Korean lyric ratio is nearly identical for boy groups on both charts.\n",
    "- Both the t-test and Mann-Whitney U test show **no significant difference** (p ≫ 0.05).\n",
    "- **Conclusion:** We fail to reject the null hypothesis; there is no significant difference in the proportion of Korean lyrics for boy groups between the Hot 100 and Global 200 charts.\n",
    "\n",
    "### **B. Girl Groups**\n",
    "\n",
    "- **Hot 100 mean kor_ratio:** 0.112  \n",
    "- **Global 200 mean kor_ratio:** 0.171  \n",
    "- **Welch’s t-test:** t = -2.00, p = 0.0498  \n",
    "- **Shapiro-Wilk normality:** Both p < 0.001 (not normal)\n",
    "- **Mann-Whitney U test:** U = 1076.00, p = 0.1995\n",
    "\n",
    "**Interpretation:**  \n",
    "- The mean Korean lyric ratio is higher for girl groups on the Global 200 (0.171) than on the Hot 100 (0.112).\n",
    "- The t-test suggests a borderline significant difference (p = 0.0498), but the data are not normal.\n",
    "- The Mann-Whitney U test, which is more appropriate, gives p = 0.1995 (**not significant**).\n",
    "- **Conclusion:** We fail to reject the null hypothesis; there is no statistically significant difference in the proportion of Korean lyrics for girl groups between the Hot 100 and Global 200 charts, although the numerical difference is notable.\n",
    "\n",
    "\n",
    "\n",
    "## 3. **How i might write this in the paper**\n",
    "\n",
    "We compared the proportion of Korean lyrics (kor_ratio) between Hot 100 and Global 200 charts for both boy and girl groups. For boy groups, the mean kor_ratio was nearly identical (Hot 100: 0.236, Global 200: 0.238), and neither Welch’s t-test (p = 0.9599) nor the Mann-Whitney U test (p = 0.8717) indicated a significant difference. For girl groups, the mean kor_ratio was higher on the Global 200 (0.171) than on the Hot 100 (0.112). While Welch’s t-test suggested a borderline significant difference (p = 0.0498), the Shapiro-Wilk test indicated that the data were not normally distributed (p < 0.001 for both groups). The Mann-Whitney U test, which does not assume normality, found no significant difference (p = 0.1995). Thus, we fail to reject the null hypothesis and conclude that there is no statistically significant difference in the proportion of Korean lyrics between the two charts for either boy or girl groups, although the difference for girl groups is numerically notable.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Why This Interpretation?**\n",
    "\n",
    "- **Statistical best practice:** When normality is violated, rely on the non-parametric test.\n",
    "- **\"Fail to reject the null hypothesis\":** Correct language when p > 0.05.\n",
    "- **Reporting means:** Shows the numerical trend, even if not statistically significant.\n",
    "- **Reporting both tests:** Demonstrates rigor and transparency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot of kor_ratio by chart and gender\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hot100['Chart'] = 'Hot 100'\n",
    "global200['Chart'] = 'Global 200'\n",
    "combined = pd.concat([hot100, global200])\n",
    "\n",
    "sns.boxplot(x='Chart', y='kor_ratio', hue='Gender_enc', data=combined, showfliers=False)\n",
    "plt.title('Korean Lyric Ratio by Chart and Gender')\n",
    "plt.xlabel('Chart')\n",
    "plt.ylabel('Korean Lyric Ratio')\n",
    "plt.legend(title='Gender (0=Boy, 1=Girl)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7420715,
     "sourceId": 11863329,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
